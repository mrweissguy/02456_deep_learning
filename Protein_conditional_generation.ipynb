{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Protein conditional generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkvoZzKScFoT",
        "colab_type": "text"
      },
      "source": [
        "# Generating proteins with a conditional character-level RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW_oM0igUe8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import random\n",
        "import time\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmmyrMy7Tkmu",
        "colab_type": "code",
        "outputId": "4c01d061-66d8-4ec7-fc82-4068c9b30ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
        "\n",
        "if use_cuda:\n",
        "  dvc = torch.cuda.current_device()\n",
        "  print(torch.cuda.get_device_name(dvc))\n",
        "  print(torch.cuda.get_device_capability(dvc))\n",
        "  print(torch.cuda.get_device_properties(dvc))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running GPU.\n",
            "Tesla P4\n",
            "(6, 1)\n",
            "_CudaDeviceProperties(name='Tesla P4', major=6, minor=1, total_memory=7611MB, multi_processor_count=20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMtN-gJ9gYGH",
        "colab_type": "text"
      },
      "source": [
        "## Prep data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baNlmTbjg5ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO: optimization of all_letters: instead of having the whole alphabet of small and captial letters, then get the set of letters that is present in the files\n",
        "\n",
        "all_letters = string.ascii_uppercase\n",
        "n_letters = len(all_letters) + 1 # Plus EOS marker\n",
        "EOS = n_letters - 1 # get index of EOS symbol"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L40oY8IhGEs",
        "colab_type": "code",
        "outputId": "962da024-ddac-4088-caa9-6c002a725e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_letters"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXoWdZaMhDP7",
        "colab_type": "code",
        "outputId": "786a526b-6b3f-4763-889d-168e691fa451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "EOS"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6uBedvscLDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read a file and split into lines\n",
        "def read_lines(filename):\n",
        "  lines = open(filename).read().strip().split('\\n')\n",
        "  lines = [line.replace(' ','') for line in lines] # remove space between the characters\n",
        "  return lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diLzQvQY4B-L",
        "colab_type": "text"
      },
      "source": [
        "Remember to upload the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoCyVziJctIx",
        "colab_type": "code",
        "outputId": "b43dbf41-6a5b-4bed-d501-0de74761700a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test read of file\n",
        "test = read_lines('./protein-datasets/arc_full/train.txt')\n",
        "print(len(test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYDahWn0dshM",
        "colab_type": "code",
        "outputId": "76452751-0c43-4be7-a81f-e438c786ad9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# find the categories, i.e. protein groups\n",
        "all_categories = list()\n",
        "path = './protein-datasets/'\n",
        "\n",
        "for foldername in glob.glob(path + '*'):\n",
        "  categ = foldername.replace(path,'').replace('_full','')\n",
        "  #print(categ)\n",
        "  all_categories.append(categ)\n",
        "\n",
        "print('found protein categories: {}'.format(all_categories))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found protein categories: ['vir', 'bac', 'arc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgTl-Lqaf9S5",
        "colab_type": "code",
        "outputId": "ba6526e2-d939-4bac-f21f-90e2277366a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_categories = len(all_categories)\n",
        "print('Nr. of protein groups (categories) =>', n_categories)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nr. of protein groups (categories) => 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H61cSQWKcyV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the category_lines dict, a list of lines per category\n",
        "category_lines = dict()\n",
        "\n",
        "for categ in all_categories:\n",
        "  for file in glob.glob(path + categ + '_full/train.txt'):\n",
        "    lines = read_lines(file)\n",
        "    category_lines[categ] = lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsDhKcx2gJFu",
        "colab_type": "code",
        "outputId": "a1beee29-dd6e-45d0-a094-e74e5f3f0511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(category_lines['arc'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idFV9nlcOnFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "359eb718-9c19-44ce-ea7a-7d41bedaf4b6"
      },
      "source": [
        "for categ in all_categories:\n",
        "  print(glob.glob(path + categ + '_full/train.txt'))\n",
        "  print(glob.glob(path + categ + '_full/valid.txt'))\n",
        "  print(glob.glob(path + categ + '_full/test.txt'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['./protein-datasets/vir_full/train.txt']\n",
            "['./protein-datasets/vir_full/valid.txt']\n",
            "['./protein-datasets/vir_full/test.txt']\n",
            "['./protein-datasets/bac_full/train.txt']\n",
            "['./protein-datasets/bac_full/valid.txt']\n",
            "['./protein-datasets/bac_full/test.txt']\n",
            "['./protein-datasets/arc_full/train.txt']\n",
            "['./protein-datasets/arc_full/valid.txt']\n",
            "['./protein-datasets/arc_full/test.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZgRnBvk5P0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d9e2b479-d489-4f65-9093-f21594d954a7"
      },
      "source": [
        "# average, max and min length of protein sequence overall\n",
        "total_seq_len = 0\n",
        "max_seq_len = 0\n",
        "min_seq_len = 99999\n",
        "total_seq = 0\n",
        "\n",
        "for categ in all_categories:\n",
        "  for file in glob.glob(path + categ + '_full/train.txt'):\n",
        "    lines = read_lines(file)\n",
        "    total_seq = total_seq + len(lines)\n",
        "    for line in lines:\n",
        "      total_seq_len = total_seq_len + len(line)\n",
        "      if len(line) > max_seq_len:\n",
        "        max_seq_len = len(line)\n",
        "      elif len(line) < min_seq_len:\n",
        "        min_seq_len = len(line)\n",
        "  for file in glob.glob(path + categ + '_full/valid.txt'):\n",
        "    lines = read_lines(file)\n",
        "    total_seq = total_seq + len(lines)\n",
        "    for line in lines:\n",
        "      total_seq_len = total_seq_len + len(line)\n",
        "      if len(line) > max_seq_len:\n",
        "        max_seq_len = len(line)\n",
        "      elif len(line) < min_seq_len:\n",
        "        min_seq_len = len(line)\n",
        "  for file in glob.glob(path + categ + '_full/test.txt'):\n",
        "    lines = read_lines(file)\n",
        "    total_seq = total_seq + len(lines)\n",
        "    for line in lines:\n",
        "      total_seq_len = total_seq_len + len(line)\n",
        "      if len(line) > max_seq_len:\n",
        "        max_seq_len = len(line)\n",
        "      elif len(line) < min_seq_len:\n",
        "        min_seq_len = len(line)\n",
        "\n",
        "print(\"total seq length:\", total_seq_len)\n",
        "print(\"total number of sequences:\", total_seq)\n",
        "print(\"avg sequence lenght:\", total_seq_len / total_seq)\n",
        "print(\"max sequence length:\", max_seq_len)\n",
        "print(\"min sequence length:\", min_seq_len)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total seq length: 46585269\n",
            "total number of sequences: 103382\n",
            "avg sequence lenght: 450.61295970284965\n",
            "max sequence length: 16990\n",
            "min sequence length: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHsU2Zm55WA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a8ee694f-24aa-4eea-e768-1595210392a2"
      },
      "source": [
        "# average, min and max length of protein sequence in each domain - bacteria\n",
        "total_seq_len = 0\n",
        "max_seq_len = 0\n",
        "min_seq_len = 99999\n",
        "total_seq = 0\n",
        "\n",
        "# bac\n",
        "lines = read_lines(glob.glob(path + 'bac' + '_full/train.txt')[0])\n",
        "total_seq = total_seq + len(lines)\n",
        "for line in lines:\n",
        "  total_seq_len = total_seq_len + len(line)\n",
        "  if len(line) > max_seq_len:\n",
        "    max_seq_len = len(line)\n",
        "  elif len(line) < min_seq_len:\n",
        "    min_seq_len = len(line)\n",
        "lines = read_lines(glob.glob(path + 'bac' + '_full/valid.txt')[0])\n",
        "total_seq = total_seq + len(lines)\n",
        "for line in lines:\n",
        "  total_seq_len = total_seq_len + len(line)\n",
        "  if len(line) > max_seq_len:\n",
        "    max_seq_len = len(line)\n",
        "  elif len(line) < min_seq_len:\n",
        "    min_seq_len = len(line)\n",
        "lines = read_lines(glob.glob(path + 'bac' + '_full/test.txt')[0])\n",
        "total_seq = total_seq + len(lines)\n",
        "for line in lines:\n",
        "  total_seq_len = total_seq_len + len(line)\n",
        "  if len(line) > max_seq_len:\n",
        "    max_seq_len = len(line)\n",
        "  elif len(line) < min_seq_len:\n",
        "    min_seq_len = len(line)\n",
        "\n",
        "print('-- bacteria --')\n",
        "print(\"total seq length:\", total_seq_len)\n",
        "print(\"total number of sequences:\", total_seq)\n",
        "print(\"avg sequence lenght:\", total_seq_len / total_seq)\n",
        "print(\"max sequence length:\", max_seq_len)\n",
        "print(\"min sequence length:\", min_seq_len)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- bacteria --\n",
            "total seq length: 34113615\n",
            "total number of sequences: 69785\n",
            "avg sequence lenght: 488.8387905710396\n",
            "max sequence length: 16990\n",
            "min sequence length: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58byn5nhRz9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "31211208-551d-44fe-968d-110a2bdb4a21"
      },
      "source": [
        "# average, min and max length of protein sequence in each domain - vira\n",
        "total_seq_len = 0\n",
        "max_seq_len = 0\n",
        "min_seq_len = 99999\n",
        "total_seq = 0\n",
        "\n",
        "# vir\n",
        "lines = read_lines(glob.glob(path + 'vir' + '_full/train.txt')[0])\n",
        "total_seq = total_seq + len(lines)\n",
        "for line in lines:\n",
        "  total_seq_len = total_seq_len + len(line)\n",
        "  if len(line) > max_seq_len:\n",
        "    max_seq_len = len(line)\n",
        "  elif len(line) < min_seq_len:\n",
        "    min_seq_len = len(line)\n",
        "lines = read_lines(glob.glob(path + 'vir' + '_full/valid.txt')[0])\n",
        "total_seq = total_seq + len(lines)\n",
        "for line in lines:\n",
        "  total_seq_len = total_seq_len + len(line)\n",
        "  if len(line) > max_seq_len:\n",
        "    max_seq_len = len(line)\n",
        "  elif len(line) < min_seq_len:\n",
        "    min_seq_len = len(line)\n",
        "lines = read_lines(glob.glob(path + 'vir' + '_full/test.txt')[0])\n",
        "total_seq = total_seq + len(lines)\n",
        "for line in lines:\n",
        "  total_seq_len = total_seq_len + len(line)\n",
        "  if len(line) > max_seq_len:\n",
        "    max_seq_len = len(line)\n",
        "  elif len(line) < min_seq_len:\n",
        "    min_seq_len = len(line)\n",
        "\n",
        "print('-- vira --')\n",
        "print(\"total seq length:\", total_seq_len)\n",
        "print(\"total number of sequences:\", total_seq)\n",
        "print(\"avg sequence lenght:\", total_seq_len / total_seq)\n",
        "print(\"max sequence length:\", max_seq_len)\n",
        "print(\"min sequence length:\", min_seq_len)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- vira --\n",
            "total seq length: 11387848\n",
            "total number of sequences: 30283\n",
            "avg sequence lenght: 376.04755143149623\n",
            "max sequence length: 7180\n",
            "min sequence length: 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnxCYBoISjj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3ebbb0db-1b70-4099-a52c-903e0f9b6c90"
      },
      "source": [
        "# average, min and max length of protein sequence in each domain - archaeas\n",
        "total_seq_len = 0\n",
        "max_seq_len = 0\n",
        "min_seq_len = 99999\n",
        "total_seq = 0\n",
        "\n",
        "# vir\n",
        "lines = read_lines(glob.glob(path + 'arc' + '_full/train.txt')[0])\n",
        "total_seq = total_seq + len(lines)\n",
        "for line in lines:\n",
        "  total_seq_len = total_seq_len + len(line)\n",
        "  if len(line) > max_seq_len:\n",
        "    max_seq_len = len(line)\n",
        "  elif len(line) < min_seq_len:\n",
        "    min_seq_len = len(line)\n",
        "lines = read_lines(glob.glob(path + 'arc' + '_full/valid.txt')[0])\n",
        "total_seq = total_seq + len(lines)\n",
        "for line in lines:\n",
        "  total_seq_len = total_seq_len + len(line)\n",
        "  if len(line) > max_seq_len:\n",
        "    max_seq_len = len(line)\n",
        "  elif len(line) < min_seq_len:\n",
        "    min_seq_len = len(line)\n",
        "lines = read_lines(glob.glob(path + 'arc' + '_full/test.txt')[0])\n",
        "total_seq = total_seq + len(lines)\n",
        "for line in lines:\n",
        "  total_seq_len = total_seq_len + len(line)\n",
        "  if len(line) > max_seq_len:\n",
        "    max_seq_len = len(line)\n",
        "  elif len(line) < min_seq_len:\n",
        "    min_seq_len = len(line)\n",
        "\n",
        "print('-- archaeas --')\n",
        "print(\"total seq length:\", total_seq_len)\n",
        "print(\"total number of sequences:\", total_seq)\n",
        "print(\"avg sequence lenght:\", total_seq_len / total_seq)\n",
        "print(\"max sequence length:\", max_seq_len)\n",
        "print(\"min sequence length:\", min_seq_len)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- archaeas --\n",
            "total seq length: 1083806\n",
            "total number of sequences: 3314\n",
            "avg sequence lenght: 327.038624019312\n",
            "max sequence length: 2951\n",
            "min sequence length: 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwE-IBpUgaed",
        "colab_type": "text"
      },
      "source": [
        "## Create net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doA4fxtlgbyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size)\n",
        "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax()\n",
        "    \n",
        "    def forward(self, category, input, hidden):\n",
        "        input_combined = torch.cat((category, input, hidden), 1)\n",
        "        hidden = self.i2h(input_combined)\n",
        "        output = self.i2o(input_combined)\n",
        "        output_combined = torch.cat((hidden, output), 1)\n",
        "        output = self.o2o(output_combined)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(1, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYVGoIw0gfr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function to get random pars of (category, line)\n",
        "# Get a random category and random line from that category\n",
        "def random_training_pair():\n",
        "    category = random.choice(all_categories)\n",
        "    line = random.choice(category_lines[category])\n",
        "    return category, line"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suwHA_H5hw39",
        "colab_type": "code",
        "outputId": "e2d38655-d6dc-4c3c-be1d-3f8f34a6148f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "random_training_pair()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('vir',\n",
              " 'MENRWQVMIVWQVDRMRIRTWKSLVKHHMYVSGKAKKWLYKHHYESTNPRISSEVHIPLGEASLVVTTYWGLHTGERNWHLGQGVSIEWGKKRYSTQVDPGLADQLIHLYYFDCFSESAIRHAILGHRVRPSCEYQAGHNKVGFLQYLALAALLTPKKIKPPLPSVTKLTEDRWNKPQRTKGHRGSHTMNGH')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHSnt64cgpMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot vector for category\n",
        "def make_category_input(category):\n",
        "    li = all_categories.index(category)\n",
        "    tensor = torch.zeros(1, n_categories)\n",
        "    tensor[0][li] = 1\n",
        "    return Variable(tensor)\n",
        "\n",
        "# One-hot matrix of first to last letters (not including EOS) for input\n",
        "def make_chars_input(chars):\n",
        "    tensor = torch.zeros(len(chars), n_letters)\n",
        "    for ci in range(len(chars)):\n",
        "        char = chars[ci]\n",
        "        tensor[ci][all_letters.find(char)] = 1\n",
        "    tensor = tensor.view(-1, 1, n_letters)\n",
        "    return Variable(tensor)\n",
        "\n",
        "# LongTensor of second letter to end (EOS) for target\n",
        "def make_target(line):\n",
        "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
        "    letter_indexes.append(n_letters - 1) # EOS\n",
        "    tensor = torch.LongTensor(letter_indexes)\n",
        "    return Variable(tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiI_S6yOiOvp",
        "colab_type": "code",
        "outputId": "0adc61fe-0342-4c14-c0d5-26650fb663f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# make onehot encoding of category\n",
        "make_category_input(all_categories[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXQr2iRUi8Gj",
        "colab_type": "code",
        "outputId": "75e9dc76-4266-459f-a9f4-9df5ead5aac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "make_chars_input(category_lines['arc'][0]).shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([570, 1, 27])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Naxfkpl_hMqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make category, input, and target tensors from a random category, line pair\n",
        "def random_training_set():\n",
        "    category, line = random_training_pair()\n",
        "    category_input = make_category_input(category)\n",
        "    line_input = make_chars_input(line)\n",
        "    line_target = make_target(line)\n",
        "    return category_input, line_input, line_target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rScxPeD1hOZt",
        "colab_type": "code",
        "outputId": "6eef8e02-c42b-4427-f5ab-64bf078095b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "category_input, line_input, line_target = random_training_set()\n",
        "\n",
        "print(line_target)\n",
        "\n",
        "#for i in range(line_target.size()[0]):\n",
        "  #print(line_target[i])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([17, 17,  0, 21, 21, 18, 18, 18, 15, 15, 15, 18, 24,  4, 18, 21, 12,  0,\n",
            "        16,  0, 19, 11,  4, 21, 15,  5, 21, 15, 15, 17, 24, 12,  0, 15, 19,  4,\n",
            "         6, 17, 13, 18,  8, 17, 24, 18,  4, 11,  0, 15, 16, 24,  3, 19, 19, 17,\n",
            "        21, 24, 11, 21,  3, 13, 10, 18,  0,  3,  8,  0, 18, 11, 13, 24, 16, 13,\n",
            "         3,  7, 18, 13,  5, 11, 19, 19, 21, 21, 16, 13, 13,  3,  5, 19, 15,  0,\n",
            "         4,  0, 18, 19, 16, 19,  8, 13,  5,  3,  4, 17, 18, 17, 22,  6,  6,  3,\n",
            "        11, 10, 19,  8, 11,  7, 19, 13, 12, 15, 13, 21, 13,  4, 24, 12,  5, 19,\n",
            "        18, 10,  5, 10,  0, 17, 21, 12, 21,  0, 17, 10,  7, 15, 10,  3, 21,  3,\n",
            "         0, 18,  3, 11, 18, 10,  3,  8, 11,  4, 24,  3, 22,  5,  4,  5, 19, 11,\n",
            "        15,  4,  6, 13,  5, 18,  4, 19, 12, 19,  8,  3, 11, 12, 13, 13,  0,  8,\n",
            "        11,  4, 13, 24, 11, 16, 21,  6, 17, 16, 13,  6, 21, 11,  4, 18,  3,  8,\n",
            "         6, 21, 10,  5,  3, 18, 17, 13,  5, 10, 11,  6, 22,  3, 15, 21, 19, 10,\n",
            "        11, 21, 12, 15,  6, 21, 24, 19, 24,  4,  0,  5,  7, 15,  3, 21, 21, 11,\n",
            "        11, 15,  6,  2,  6, 21,  3,  5, 19,  4, 18, 17, 11, 18, 13, 11, 11,  6,\n",
            "         8, 17, 10, 10, 16, 15,  5, 16,  4,  6,  5, 17,  8, 12, 24,  4,  3, 11,\n",
            "        21,  6,  6, 13,  8, 15,  0, 11, 11, 13, 21, 10,  4, 24, 11, 10,  3, 10,\n",
            "         4,  4,  0,  6, 19,  0,  3,  0, 13, 19,  8, 10,  0, 16, 13,  3,  0, 21,\n",
            "        15, 17,  6,  3, 13, 24,  0, 18,  0,  0,  4,  0, 10,  0,  0,  6, 10,  4,\n",
            "         8,  4, 11, 10,  0,  8, 11, 10,  3,  3, 18, 13, 17, 18, 24, 13, 21,  8,\n",
            "         4,  6, 19, 19,  3, 19, 11, 24, 17, 18, 22, 24, 11, 18, 24, 19, 24,  6,\n",
            "         3, 15,  4, 10,  6, 21, 16, 18, 22, 19, 11, 11, 19, 19, 15,  3, 21, 19,\n",
            "         2,  6,  0,  4, 16, 21, 24, 22, 18, 11, 15,  3, 11, 12, 16,  3, 15, 21,\n",
            "        19,  5, 17, 18, 19, 16, 16, 21, 18, 13, 24, 15, 21, 21,  6,  0,  4, 11,\n",
            "        12, 15,  5, 17,  0, 10, 18,  5, 24, 13,  3, 11,  0, 21, 24, 18, 16, 11,\n",
            "         8, 17, 18, 24, 19, 18, 11, 19,  7, 21,  5, 13, 17,  5, 15,  3, 13, 16,\n",
            "         8, 11,  2, 17, 15, 15,  0, 15, 19,  8, 19, 19, 21, 18,  4, 13, 21, 15,\n",
            "         0, 11, 19,  3,  7,  6, 19, 11, 15, 11, 17, 18, 18,  8, 17,  6, 21, 16,\n",
            "        17, 21, 19, 21, 19,  3,  0, 17, 17, 17, 19,  2, 15, 24, 21, 24, 10,  0,\n",
            "        11,  6,  8, 21,  0, 15, 17, 21, 11, 18, 18, 17, 19,  5, 26])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHdfu2CXhPIH",
        "colab_type": "text"
      },
      "source": [
        "## Training the net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bba10UnNhQkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
        "    hidden = rnn.init_hidden()\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0\n",
        "    \n",
        "    for i in range(input_line_tensor.size()[0]):\n",
        "      if use_cuda:\n",
        "        output, hidden = rnn(category_tensor.cuda(), input_line_tensor[i].cuda(), hidden.cuda())\n",
        "        #loss += criterion(output, target_line_tensor[i])\n",
        "        loss += criterion(output, torch.LongTensor([target_line_tensor[i]]).cuda())\n",
        "      else:\n",
        "        output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
        "        loss += criterion(output, torch.LongTensor([target_line_tensor[i]]))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    #return output, loss.data[0] / input_line_tensor.size()[0]\n",
        "    return output, loss.data.item() / input_line_tensor.size()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mbffkYRhSeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to keep track of how long training takes\n",
        "def time_since(t):\n",
        "    now = time.time()\n",
        "    s = now - t\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ScqsLqDhdEU",
        "colab_type": "code",
        "outputId": "0c228cb2-6d1b-47b1-a3e4-40a793a7a252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "n_epochs = 1000\n",
        "print_every = 50\n",
        "plot_every = 50\n",
        "all_losses = list()\n",
        "all_epochs = list()\n",
        "loss_avg = 0 # Zero every plot_every epochs to keep a running average\n",
        "learning_rate = 0.0005\n",
        "\n",
        "#rnn = RNN(n_letters, 128, n_letters)\n",
        "rnn = RNN(n_letters, 512, n_letters)\n",
        "if use_cuda:\n",
        "  rnn.cuda()\n",
        "  print('Using GPU %s with compute capability %s' % (torch.cuda.get_device_name(dvc),torch.cuda.get_device_capability(dvc)))\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    output, loss = train(*random_training_set())\n",
        "    loss_avg += loss\n",
        "    \n",
        "    if epoch % print_every == 0:\n",
        "        print('%s (%d %d%%) %.4f' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "\n",
        "    if epoch % plot_every == 0:\n",
        "        all_losses.append(loss_avg / plot_every)\n",
        "        all_epochs.append(epoch)\n",
        "        loss_avg = 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU Tesla K80 with compute capability (3, 7)\n",
            "0m 19s (50 5%) 3.1717\n",
            "0m 36s (100 10%) 2.9321\n",
            "0m 50s (150 15%) 2.9300\n",
            "1m 7s (200 20%) 2.9316\n",
            "1m 24s (250 25%) 2.9471\n",
            "1m 38s (300 30%) 2.9755\n",
            "1m 53s (350 35%) 2.9152\n",
            "2m 7s (400 40%) 2.9209\n",
            "2m 24s (450 45%) 2.8163\n",
            "2m 39s (500 50%) 2.9052\n",
            "2m 55s (550 55%) 2.9412\n",
            "3m 15s (600 60%) 2.8682\n",
            "3m 34s (650 65%) 2.8594\n",
            "3m 49s (700 70%) 2.9405\n",
            "4m 2s (750 75%) 2.8676\n",
            "4m 17s (800 80%) 2.8739\n",
            "4m 32s (850 85%) 2.9408\n",
            "4m 46s (900 90%) 2.8544\n",
            "5m 1s (950 95%) 2.9420\n",
            "5m 19s (1000 100%) 2.9489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqlVWt1z-DXa",
        "colab_type": "code",
        "outputId": "cfef0cc6-9b2e-440f-95db-943c3e9a62bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(all_epochs,all_losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCQgFuohIQCjQRUQCQoEuIhIQ/x/cUp8x6JlTCwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiRoDrpEOCJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICTQTlF_ODNu",
        "colab_type": "text"
      },
      "source": [
        "## Samling the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ogXrqvzOEzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 6000\n",
        "\n",
        "# Generate given a category and starting letter\n",
        "def generate_one(category, start_char='A', temperature=0.5):\n",
        "    category_input = make_category_input(category)\n",
        "    chars_input = make_chars_input(start_char)\n",
        "    rnn.cpu() # move back to cpu\n",
        "    hidden = rnn.init_hidden()\n",
        "\n",
        "    output_str = start_char\n",
        "\n",
        "    for i in range(max_length):\n",
        "      if False: #use_cuda:\n",
        "        output, hidden = rnn(category_input.cuda(), chars_input[0].cuda(), hidden.cuda())\n",
        "      else:\n",
        "        output, hidden = rnn(category_input, chars_input[0], hidden)\n",
        "        \n",
        "        # Sample as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Stop at EOS, or add to output_str\n",
        "        if top_i == EOS:\n",
        "            break\n",
        "        else:    \n",
        "            char = all_letters[top_i]\n",
        "            output_str += char\n",
        "            chars_input = make_chars_input(char)\n",
        "\n",
        "    return output_str\n",
        "\n",
        "# Get multiple samples from one category and multiple starting letters\n",
        "def generate(category, start_chars='ABC'):\n",
        "    for start_char in start_chars:\n",
        "        print(generate_one(category, start_char))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMS2zRUUOTz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#res = generate('arc', 'A')\n",
        "#print(len(res))\n",
        "#print(res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf7snQQuOWdK",
        "colab_type": "code",
        "outputId": "99cb5039-2c92-4455-c2dd-0724655adcbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "res = generate_one('arc', 'M')\n",
        "print(len(res))\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3016\n",
            "MNILHFGLIKTGVGDIGVTVVLPAPNPFVVDITINNYGDNALFLEIPIVYESVNEVLKERENFILRVVKLYKEFEEAAKEILVIVSDGYYFDVDVALGAAVGKISKEDEIIVKAIGDLVIITSLMTVIFEMESILDCKEVEVLVKDAVGLGRATAEEKGGGVVIKLTREVLLSDGRGPDLRRKAVIIGKSEYAIPVIYKDVYAVEWSVKDESAYLLGIEDIIDNTSLRKLGDLGAEGKPLVVKEYDLAAVELEDKALGRELKIAKPEALEYAIAALKGLETQESVSFAVPPKDVVSELAEKFKTRAKEGLTARGLLLKGATGSAVEFESKGKRAARTFDSDVLEGIGELKTKLVIIGVVEGAVGAAAIRVELDIIKRIVLSIVRTVKDSVLETLAQLSGVELYALVKGAIKVRVGMIKPTIYNEKTFDVLGLNTIASDRVAVVLALPEDGRELGIPGLKKLRSEELDARTDRVNRVRYEIVRAIELIEGVGVEERLIENILILEQAFVPKDIRIAAKAHLRAVSHVEELRRISLIKPIGTGAPYAVLGLENAVPAPILAVKDLIVEIKVAIVEEEEERKLGTAIILEGMEYKGTFLVRKLDAEGDYREGGNKIEKNVGVDEEKMGYQADLGKFRLEEPKAVPKAYVGIDGKGSSAGVLGRRLTVLASDLVDLLGVSGVVHPIEGKIKELEADAEKRENYLKTFLNRKEGKIKRKELYKAATVSVLLNEAEERSKPLEEVEVITKVFSVVAGLDVHIFIPVIIGEGSEDKLSIIALSTVDGKARKKFTDLEKARKLRVSVIKEMDDREVTDFDFGIKLIPIPYGAQYAGEPGGFSRIIPEDEPGDFGETIKRGVERLHETELDIEGVPGKYEEISQAAVEKGGFGVLIRDLILKIVNYALNNFVGEKLYKHTMVRGRNRGENIKVKLGLAQTEEALVEFKVERRAGRIESEDSKEAIPVVLVRNPYTDIKVITGRVVTDGAALTGGDAADGIAEGLGKLGAAGLKDAMLIEADREAAVECLTGGRYTIAGKIIHPKEVDVVEASLLGASCVPEGAPGEVDTLYFLLLLADDLHKLKYTEINERKDGFPRSKVLLASFRIIRLTEKDEGFMNNKAAVSVVVYLGSFKLILRKLRQGLIVIVPITIEVLTKTIGEKGRIQVGETLDVVLLVKLEIRIDGGRARLIKLGKTVSKGAALLDIEELGAIRFIPSLELVAAVGDVLVVAILGVCVGDVADLEVALLRSLGEHEMTVEEILPLLKILITIEDDIELIGAEADADERLVAIKLGRLLDYAVVVLKSGLNKAEARRVKIVPKAAVKYARLVEKAKAHDLGRLIPIKFKKDKFLLDRDIGNVEVKVELKHGKVIRDKVLPYAAEYIFILVVEDGEEAATERAEYAERTREALPSIIVRKVEKDRVKERKPQLLTKKLLRPVVGVEREIFIARKFRLDVAILEDLLCVALRVYITKVWVVPAINKLYELRAAGPLGGKGPPVEYRLKELNTVPIARLGVRVDIRDLEFLIRKQRAFIEDKAASRITGAGLNILRRIERKGVRIGMATNEGVLEKVNLSRREIRADVLVVRKVSVHADLIINNEEVLLRPYTSKIAIRFLARELVIIVGGLVDELETKIVDYRASFAAPLEGGKGLVFGKPHIKTSLYYVKIVEKTLKKPVRFFRKIRKVVDGEPLRFLEEVNALLGIRILPKAPLISVRKELEIVRLIILDIAVEEVDERFLAAVLKVEPDSPGGYLDILLSIEVINTKAAVSFSNNIRKADLAKLEEELRLSTYVYTVYELLPIAQLSRSLLGAGTNYKPLENALKSVGIAIVGAILEGEDAFTSLGAIFRRKMAVAAGISVDLTDDTSVEEVGFREDVPETKIRSGTSVVVGADVKIGRPGAGILGDLLIAGAKTDEDALLEGKGEIETIPDDSKMGGKVKERKIANALVRLLLEMVLLAVQVVDDRKEGIGEEPKHIIEPVIAVAIEEKDLIEDEEPAVAGRKRLIDAPLLERGLIPDAIVAEVLIVIVGVSEEDLAHVYVVEIVIKIAAKDERLIREDVQAAGEELLEEVTVKELDEGGVKPVEPTEYHNKIVKVCILIITAFKSVIGIMGEDEGMVIKPILALYIFAASLVLAPTEDPREVRIVEDGVKIAITGLETGVITFGIKLTLKPDEQILDTVAVITLSLVILRAEKEVEALYADPDGSVSYGVISLRDGLGLLHIAVGLILGFILIVRASFLVIPGLVKVHELVDVLENKRYKRKIGEALYLFLDLASGVKEVRDETLISKREGKDAPLYKGENDLLQYAFAVSVTGIAVASHRFYIKKELISNALILGKVLLTSKGKLAMIILVETLVLFFEVIGVLIRNVTKKEEEYAEHKKLIPNAEAFGKAKRDVGLTVKRLGSVLEISLISKILPETRAVKLTKKKVLAPQDAIYGGAGLKEGDEGEENTYLPVEGVLDLGALVDHMTALGVIIRVGELKDDAIIALVYKSEILVKLPKKALVVKGRVLRKVMGTDDDTILALDLVLAEEDGTYVILIAKAEGLIKIAESKKEWVLSIIEPGPDEKRIKEKLYFILPLNSPGFEVKEALVLTIEGLAPSKKATVLLEGAIRRAAADLLFIAVNLEKLLIGETVYLSVEVVSSEIRVEDLLDPELVVEDERKSIYVKVLDAGIYVVSDGEYGLVPLLYLASLGFEPADLLVALETGGYEAGEVLVVASKNLLSGVVALIDGNDLGDIVTPKALPVIPEREILFFEILAVLVLVKEDLEVLGEKAIKVVTTGLRGKILLYTVKKRKLTWFNESSGLKRVRAALVKGDGLLESGDGNKKGNGAIGYGLAISESGIEIDEVGSKVKSVVAIEEDHLPDLLAGVLAREAEKRKDVESRYKDDEKNELEYSALDSKKLTGLLGGRPVKVNRKMYYEEAVVEEKIIHVIEYFDFALVRRKKKVYEAVSLEGRDKLKEVLIYVSEKLLAGIGDEGVVILGPGKAVKTGGTFPATASKLEWFITDAFGKKLDFGILDVPLI\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onXmwBmEPbda",
        "colab_type": "code",
        "outputId": "77a32702-fed7-4bbf-d01f-317d23f7edb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res in category_lines['arc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33iRqqamb0TE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q5YZUMSi4E9",
        "colab_type": "code",
        "outputId": "7e68fb78-bcbd-48e6-fb22-ed6d8beed156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "res = generate_one('arc', 'MAADIFAKFKKS')\n",
        "print(len(res))\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1529\n",
            "MAADIFAKFKKSEGVGATYLGFVSSPEVIPGLPDILTEVGLLVELEVEVAALCLLLAAIKIGVIILNYRLEKGMRVAIEDVDVWNVLVEDILGGNGVCVPEKAIENILSYLLILGVLAEVVEVSEEGNKVGEFLVNIGAAVIGVIVILEGEGEKLVEEHGRNEKLGLDFSIYLEEGIKALEVVVEEGLGVLARRQEARRKVGKPVAELLGHGYEGRFKEVLVDPEVVSAILDLVIILKHYGELDEDLDIEVEVTQVGLGLWGYLTGGFFDWLKLTGKAALKLAAILGGIELKKEKFVSVLPKGIRILKRLDYDEGIVDSLNYFDKLAEEILEEEEKKKGKKKAIIEVAIELAEKAKKVELEGRKRILLIKGFMYTTPGEFEDVLVSIALGEGHLYVGECFLIPDEDYEELIKPYYNLSDSHIAVGVLKVVLLTELAGGLGFKVSIPKIISGLEGLVAVISEKVEEEELGEFAILSEIIGLEALKYFDKIEGNKVKLIEVRLRKEDKYVIVSDVDIKEVGEGQVLAFLVGYVIIARENIPKKKKEIKDYEIKLGLFDSLIYKKKIGEFFEEELIELEDNVLKDQEIEELVDLGADVGIVGLVRVLVGGYSNKPIKPVDDKEEVLKNKKILKLEEALGLIVSYVDIPEFASQVINKKIADENLSSSKEVAIRGIIVGMRVGHPVSGVLEAVEEDEVGIEGRIIGGALLERLSTVLGHLIYGALFGLSAISAIVARIEEEKIVFPLIPNVCEILSEINKEEAEVGILDPVVYKTGSDAAITTAVREGGEAVEVVPKTQKIIVDWGAELYWSFDRELIRVRFRLRLTILENMVKVAQEEIRKAIVKIVGDRLDDILTEGGGWGVKRASILTHPRISLPLTARGAIAIVHAALGEDAILSVKYRKIVYENIVGREVSLELGEDAAVFLGKMGETVLVGVGLALAEAAAAAAVGDFQKLRPMTFIGLAKLAEGLDLLVEQVIELLETAGELGLKPSEIRREVHEAKEEEVLVALIPEIEDREDLTKKKGPKVLVRLVKLAKVGVIPFIESVVRIAISRLLVGEIAGEVAALEAMALVAALGLQVGLGVMGIFEREELEKEIEEEKGVEIREIGEETPIILVVVEVRAITGALGVDTISGRARVAILVGLKGTGIIKGLTGVVFPVSFELIKIEDLALEEVKGEKRKLISILGIIEEYLIATFGEIVLELADMIREEKKIASYLGAITQLAIGAAIAKIIKRIRDEIMVGKGKKTALEAVVEILGYLGNIVLEFLLAFDYLTKGLILNIVEKDKEDEEAEEAIEKENRGFILRKISEVDLDLAFKELEEGKKEEKEIEKRKQREVLAPPDPGTLEAILKEKEVEIEGGDLVILRAIVGVGIGAEIERLIKRSKILKPVVPKVPKELAGEFGKGKKVKILLGGKVSPVLGVIKDRYIAGQAAILAEEAKIKEILEVGDEYLGTFVKKGLEYIAASALAAELIAKGAKEGRILIPVISYKLTYIAILKNNTSLRLLIAIRLAGLKKKDKLINVKYPDC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb_wKzu7hhS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sKy9GqDb1X1",
        "colab_type": "code",
        "outputId": "f65cb33c-8410-4389-f88a-705e9e0313bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "res = generate_one('arc', 'gshmkmgvke'.upper())\n",
        "print(len(res))\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "416\n",
            "GSHMKMGVKEESAMAPAAMLDVVLLAVPIKSRERLGSAVRSIEGLLREAIILKSATIKGIKAIEKRLEDDRSKVDADVGATDEIAFRAIAVLAEVVREVERSRIEELKHVGGVESPLTKEFRSPIDVLEEVKEGILTAALKADKYALSNNIDIYELGVEIIGINKSREHGQKDAGKAGSIRESVELSAGEAIEIKGDKRLSVVAKRQKLTEIRKGLEITGEKSAEERLGRLLFAVDIRDVVPGKIQIHKFEPLGGVVVELMVIMGVAPLDLTHTLIDVRGEALGLREKELYIAGDSNDKVTEFIIEVEGEITARLMVRAKALLRFRPVRRYTVPELAKRRDLQKPLGVVGKFKVMVTKETGRIVELEIPLTKSSVGRIVGGVIKNVGDAGSADGGMDVLEAILRGYIRYNGVAPLG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvzt1E0fiURT",
        "colab_type": "code",
        "outputId": "560788aa-bc31-4589-bdbe-8bb5cbb1d727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "res = generate_one('arc', 'M'.upper())\n",
        "print(len(res))\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1406\n",
            "MSILKAREALLVNAKIKDIVDPDARKVKPLPAPLIEPKDSISLVAIEPLAKKGELLDLGDSIILISLILGVYKEEDALKKLFSLAAFGLRVYPAASKEDFGKKSELRHPEIGSAVNVEIEVGMAGYALAEKVAFLGAAMDDEDVEGDNMINIEKIVSFEIEKIVDKTAFYQGDLSLEDRALDLGVADEVISQVATLLVAKTKLVGEESLLTVIEVIVGIVGIARLLELKKIRPFLGLRLFERGSEDLTIEHDMEDRFVDALVSADSLGLAEVTLKEGVFIRTRLDEYISEVVSLEMLGLFDLLLDMILSRISSYSAISVNEELKRGPLAGLLGSADVAIGLGARDYIRRRIGGKPIGLYSVELRPAVPNYTYGAIGGQLTENYKIVGVLPGNAGQKVGEEPIKTISPEIALQYLSVPENALTNVLAVLEIEQGGEDLTKVETIIRIKVVIIPNKPKLALIVDVDGADEDLPPVGKVDETPLLIALIETLVSGAVSIALGTTRKAIRGQVQGLKEEAHLAIGLRAEIIPTLISLNKRVEEDGGNQLARLAVSIVVVVGPAEVIETIVSGPEVDLEAQVDHGRDRLGLEFIGDVTVGEVSTESILKIAEEESAEAQLLGEMIRFPDIGGLITMAGSNTWAGLAPLGVRIVTIDVVETAFRAIVAFIVNADRMDKFTIALGTGLNLMSAAYHLYSRLNYVDLAEGPRKVKYLPLLKTVKAIKLGKLGFDEELVADEGRWILTGSSAVEIGIAVAPILKVGVADGEYRGSENGKVLSQLVLAGALIVSKLIDSAIGIKISEIVDYEKDKLVKGLMKPPMLVRGPEARSELVVPRGISLKKLKFLDRLNLESKLKLIYRDVVVLALERNEWLVDSNIGRLVGLIVAYKYKIRVVGSNAIMALVLEMDTEAILKLAKVLKIVTYLTEWELGKQIKDKPIVLPDLIVKAGEEVDLIYLSIVEEGDSGVEILLQRDSVYGIGELGKVRDLSPIVKPYYLAAQKDELPVLGYILVSVDLLVIDTMEKRAIVSIENDEGVELIELEAGSVVAVFVYYLGEVSLANKKVALGVYSGELLAITLALKANSGIPGVRIRPRVGKTKIGGIFIPVVQTAVLDVYEDLPPGLDVEINHVVSDFFATIRIVKLGTALLKLVKSLYGTRLTMLGGLIRIFKLDKLILILKIKPGDLYADAASALGVSIKLDESIYLSIINILVLIKISSTKLVDAETRAVDGLGLLYLERNNKMAVECYKGLEKLTEKGIEDGVEDVEPYLKEVGDNSLLGGVGILLELVRLVNRIVGVIKGIYDWRLGKFTELGIVSGVSRAAGLELDQKGTKEKKRIVEDEMAGMYEATEDLPILNLPRVVIIKEHIEVVSGFKRTLELADAIKMLGSPQGSKKLVAVNNLPKVIRQVSAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWY9ZnDLktXV",
        "colab_type": "code",
        "outputId": "ed11d01f-ffd1-4439-c19f-480ff71dc6d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "res = generate_one('vir', 'M'.upper())\n",
        "print(len(res))\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "883\n",
            "MGHPMEGPALSLSGDLAVLPDLLIAVSVGPEVGIDGILLKQKLAGQTKGLKFVYDPGGQSTPKAVKIVDSLRMALVLVGQLNGDGLVVDTVRVKHATVGTRLGLDYGDGHRPAIHLCIRLLPRAEKPVGLHEWQVDLTEAGLLERQKNGGLISSHPEVTRNVQRRGWQPRRKQVGPLQNKGIEGNWRWMRRLTVEILQLVVTASHTGKGHIRVTPSVTLPRASLGPDAITLLRTRVGKAILRHMREMPKNGSEIPQLLVTLPYIPPGLGQLRGGTETQPNTWKLQGALSRPLSIGNRRNTTFAIGSSIGHMYSTVPGTGHLVVRHLSYITALPGIVKTKEVVSDNVVDSLPYLQRLKAPSKDSLIALLVMPGSALRLRPPLTLDTAQAPVARIQSSACYLGHTRLGKNPISLLGLPHMMSNSTSSAKIGPGSPLARPPIVQGYLTLPLATGHYWGTLNRYYSLWNVQKVPILRVIGTLGLIKSLYKTETGVHHGAGVTYNDTSKGALPRHQKVRNVIGTNNTAIQRALERDPSARGKNILLYARNTLDDLIRALGTLAPEIVDARERVLPQTFSTRAVATKNEGVTISAREIDTTELEYPLETHLKVFKEIPRAIILMEEIPTTVFSRIISIHTTPDVLAGLLGTLISKPLLQVDFSVDAETVGGHQVSPGPYDRVQVPRLQALTGELPTLPEADLNLEELAALTGLAASGLIPGKGKRATRAIPGHIVLIHQSSGEGNLRAWQVPNDSAFPTLPYKVGWLVEHKYPLSFLSSLTKRNITILILLYYPGLYRVNNTFATAADQVRIPREDLPSGTEENSDVTTPSKIPKTGEAEYSGDKGHNLINHIMSSLNGGPSAGILIVTGLVDKYVGTQVEAKQYRLRH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGC4pGDgjnGq",
        "colab_type": "code",
        "outputId": "94f12b71-46e1-4566-d109-a2f9f0e36bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "res in category_lines['arc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSp2BRNVhMkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}